% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/skellm_skeleton.R
\name{skellm_skeleton}
\alias{skellm_skeleton}
\title{Create a LLM skeleton}
\usage{
skellm_skeleton(
  url = class_missing,
  model = class_missing,
  history = class_missing,
  stream = class_missing,
  api_key = class_missing
)
}
\value{
An object with class \code{skell_skeleton}.
}
\description{
This class handles the creation of LLM skeletons
}
\section{Slots}{

\describe{
\item{\code{url}}{The host's URL.}

\item{\code{model}}{Identifier of the model to be used.}

\item{\code{history}}{Messages to be included in the request. By default, is an empty \code{skellm_message_history} S7 object.}

\item{\code{stream}}{Whether or not to stream the incomming response. FALSE by default.}

\item{\code{api_key}}{(Optional) The API key of the service.}
}}

\examples{
# For Ollama
skellm_skeleton(
  url = "http://localhost:11434/api/chat", 
  model = "mistral"
)

# For OpenAI
skellm_skeleton(
  url = "https://api.openai.com/v1/chat/completions", 
  model = "gpt-3.5-turbo",
  history = skellm_message_history(
    skellm_message(role = "system", content = "You are a helpful assistant"),
    skellm_message(role = "user", content = "What is 2 + 2")
  ),
  stream = TRUE,
  api_key = "<your_api_key>"
)

}
